{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pysam import VariantFile\n",
    "import seaborn as sns\n",
    "from vcf_to_df import vcf_to_df\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by:\n",
    "    > Must pass filter\n",
    "    > Must be SNV\n",
    "    > Must have an allele frequence > 0.1\n",
    "    > Must have mean postion in read > 13\n",
    "    > Must have a depth of >10\n",
    "    > Must have MAF of < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {\n",
    "    'filter':['PASS'],\n",
    "    'type':['SNV','snp'],\n",
    "    'af_min':0.1,\n",
    "    'dp_min':10,\n",
    "    'pmean_min':13,\n",
    "    'gmaf_max':0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in each VCF file and turn into pandas dataframe pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'pysam.libcbcf.VariantRecordInfo' object has no attribute 'get_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f8457665da58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvcf_to_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvcf_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'af'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'af'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/XTHS-analysis/code/notebooks/vcf_to_df/vcf_to_df.py\u001b[0m in \u001b[0;36mvcf_to_df\u001b[0;34m(vcf_file_path)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PMEAN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 rec.info.get('NM')]\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CAF'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound_caf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCAF_to_MAF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CAF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gmaf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'pysam.libcbcf.VariantRecordInfo' object has no attribute 'get_keys'"
     ]
    }
   ],
   "source": [
    "for filename in glob.iglob('/Users/DanielaNachmanson/XTHS-analysis/data/vcf/*.annotate.vcf'):\n",
    "\n",
    "    path = Path(filename)\n",
    "    df = vcf_to_df.vcf_to_df(path)\n",
    "    \n",
    "    df['af'] = df['af'].astype('float')\n",
    "    df['pmean'] = df['pmean'].astype('float')\n",
    "    df['dp'] = [int(dp) if dp else None for dp in df['dp']]\n",
    "    df['gmaf'] = [float(gmaf) if gmaf else 0 for gmaf in df['gmaf']]\n",
    "\n",
    "    df = df[df['filter'].isin(filters['filter'])]\n",
    "    df = df[df['type'].isin(filters['type'])]\n",
    "    df = df[df['af'] >= filters['af_min']]\n",
    "    df = df[df['dp'] >= filters['dp_min']]\n",
    "    df = df[df['pmean'] >= filters['pmean_min']]\n",
    "    df = df[df['gmaf'] <= filters['gmaf_max']]\n",
    "\n",
    "    if 'FRFZ' in filename:\n",
    "        df['chr'] = ['chr' + c for c in df['chr']]\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_pickle(str(path.parent) + '/pkls/' + str(path.stem) + '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c3321b4ce39d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;34m'MT'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'Y'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                 \u001b[0mout_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mout_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quals' is not defined"
     ]
    }
   ],
   "source": [
    "for filename in glob.iglob('/Users/DanielaNachmanson/XTHS-analysis/data/vcf/*.annotate.vcf'):\n",
    "#     quals = []\n",
    "    path = Path(filename)\n",
    "#     out_file = open(str(path.parent) \n",
    "#                     + '/' \n",
    "#                     + str(path.stem) \n",
    "#                     + '.filter.vcf',mode='w')\n",
    "    vcf_in = VariantFile(path)\n",
    "#     out_file.write(vcf_in.header.__str__())\n",
    "    for rec in vcf_in:\n",
    "        break\n",
    "        file.write(rec.__str__())\n",
    "    \n",
    "        filter_,qual,af,dp,type_,pmean,maf = [\"\".join(rec.filter),\n",
    "                                    rec.qual,\n",
    "                                    rec.info.get('AF'),\n",
    "                                    rec.info.get('DP'),\n",
    "                                    rec.info.get('TYPE'),\n",
    "                                    rec.info.get('PMEAN'),\n",
    "                                    vcf_to_df.CAF_to_MAF(rec.info.get('CAF'))]\n",
    "        quals.append(qual)\n",
    "        if filter_ == 'PASS' and type_ in ['SNV','snp']:\n",
    "            if float(af) > 0.1 and int(dp) >= 10:\n",
    "                if int(pmean) > 10:\n",
    "                    if not maf or float(maf) < 0.01:\n",
    "                        if int(qual) > 50:\n",
    "                            if 'MT' not in rec.contig.upper() and 'Y' not in rec.contig.upper():     \n",
    "                                out_file.write(rec.__str__())\n",
    "    plt.hist(quals)\n",
    "    plt.show()\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.iglob('/Users/DanielaNachmanson/XTHS-analysis/data/vcf/FRFZ.*.annotate.vcf'):\n",
    "    path = Path(filename)\n",
    "    out_file = open(str(path.parent) \n",
    "                    + '/' \n",
    "                    + str(path.stem) \n",
    "                    + '.DOWNSAMPLE.vcf',\n",
    "                    mode='w')\n",
    "    vcf_in = VariantFile(path)\n",
    "    out_file.write(vcf_in.header.__str__())\n",
    "    for rec in vcf_in:\n",
    "        \n",
    "        G5 = False\n",
    "        COMMON = None\n",
    "        \n",
    "        if \"SAO\" in rec.info.keys():\n",
    "            try:\n",
    "                SAO = int(rec.info.get('SAO'))\n",
    "                if SAO not in [0,1,3]:\n",
    "                    continue\n",
    "            except:\n",
    "                hi = 1\n",
    "        if \"G5\" in rec.info.keys():\n",
    "            continue\n",
    "            \n",
    "        if \"COMMON\" in rec.info.keys():\n",
    "            try:\n",
    "                COMMON = int(rec.info.get('COMMON'))\n",
    "                if COMMON == 1:\n",
    "                    continue\n",
    "            except:\n",
    "                hi = 1\n",
    "        out_file.write(rec.__str__())\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='/Users/DanielaNachmanson/XTHS-analysis/data/vcf/FRFZ-vardict.vcf'\n",
    "path = Path(filename)\n",
    "out_file = open(str(path.parent) \n",
    "                + '/' \n",
    "                + str(path.stem) \n",
    "                + '.filter.second.vcf',mode='w')\n",
    "vcf_in = VariantFile(path)\n",
    "out_file.write(vcf_in.header.__str__())\n",
    "for rec in vcf_in:\n",
    "    if rec.info.get('TYPE') != \"Complex\":\n",
    "        out_file.write(rec.__str__())\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.info.get('SAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/DanielaNachmanson/XTHS-analysis/data/vcf/F'\n",
    "path = Path(filename)\n",
    "df = vcf_to_df.vcf_to_df(path)\n",
    "\n",
    "df['af'] = df['af'].astype('float')\n",
    "df['pmean'] = df['pmean'].astype('float')\n",
    "df['dp'] = [int(dp) if dp else None for dp in df['dp']]\n",
    "df['gmaf'] = [float(gmaf) if gmaf else 0 for gmaf in df['gmaf']]\n",
    "\n",
    "df = df[df['filter'].isin(filters['filter'])]\n",
    "df = df[df['type'].isin(filters['type'])]\n",
    "df = df[df['af'] >= filters['af_min']]\n",
    "df = df[df['dp'] >= filters['dp_min']]\n",
    "df = df[df['pmean'] >= filters['pmean_min']]\n",
    "df = df[df['gmaf'] <= filters['gmaf_max']]\n",
    "\n",
    "if 'FRFZ' in filename:\n",
    "    df['chr'] = ['chr' + c for c in df['chr']]\n",
    "\n",
    "df.to_pickle(str(path.parent) + '/pkls/' + str(path.stem) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the vcf from our fresh frozen exome data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frfz_in = VariantFile('/Volumes/oncogxA/Projects/ATHENA/MCLU01/Experiments/Development/DNA-seq/pilot0514/FRFZ/FRFZ-vardict.vcf.gz') \n",
    "\n",
    "lst_ = []\n",
    "\n",
    "for rec in frfz_in:\n",
    "    rec = rec\n",
    "    entry = [rec.contig,\n",
    "            rec.start,\n",
    "            rec.stop,\n",
    "            rec.ref,\n",
    "            rec.id,\n",
    "            rec.alts[0],\n",
    "            \",\".join(rec.filter.keys()),\n",
    "            rec.qual,\n",
    "            rec.info.get('QUAL'),\n",
    "            rec.info.get('AF')[0],\n",
    "            rec.info.get('DP'),\n",
    "            rec.info.get('VD'),\n",
    "            rec.info.get('TYPE'),\n",
    "            rec.info.get('PMEAN'),\n",
    "            rec.info.get('NM'),]\n",
    "    lst_.append(entry)\n",
    "\n",
    "frfz_df = pd.DataFrame(np.row_stack(lst_),columns=['chr','start','stop','ref','id','alt','filter','qual','vd_qual','af','dp','vd','type','pmean','nm'])\n",
    "\n",
    "frfz_df = frfz_df[(frfz_df['type'] == 'snp') | (frfz_df['type'] == 'SNV')]\n",
    "frfz_df = frfz_df[~frfz_df['chr'].str.startswith('G')]\n",
    "frfz_df['af'] = frfz_df['af'].astype('float')\n",
    "frfz_df['pmean'] = frfz_df['pmean'].astype('float')\n",
    "frfz_df['dp'] = frfz_df['dp'].astype('float')\n",
    "frfz_df['chr'] = ['chr' + c for c in frfz_df['chr']]\n",
    "\n",
    "frfz_df = frfz_df[frfz_df['filter'] == 'PASS']\n",
    "\n",
    "frfz_df.to_pickle('/Users/DanielaNachmanson/XTHS-analysis/data/vcf/pkls/FRFZ-vardict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.iglob('/Users/DanielaNachmanson/XTHS-analysis/data/vcf/*.filter.filter.second.vcf'):\n",
    "\n",
    "    path = Path(filename)\n",
    "    df = vcf_to_df.vcf_to_df(path)\n",
    "    \n",
    "    df['af'] = df['af'].astype('float')\n",
    "    df['pmean'] = df['pmean'].astype('float')\n",
    "    df['dp'] = [int(dp) if dp else None for dp in df['dp']]\n",
    "\n",
    "    if 'FRFZ' in filename:\n",
    "        df['chr'] = ['chr' + c for c in df['chr']]\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_pickle(str(path.parent) + '/pkls/' + str(path.stem) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
